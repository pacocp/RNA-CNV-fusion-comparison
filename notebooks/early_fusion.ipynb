{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a23db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, f1_score\n",
    "import xgboost as xgb\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aca0ca4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../RNA-Seq/RNA-ExpAll-LC.csv.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-446f5b8b63a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_rna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../RNA-Seq/RNA-ExpAll-LC.csv.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/multiomic-classification-NSCLC/env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multiomic-classification-NSCLC/env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multiomic-classification-NSCLC/env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multiomic-classification-NSCLC/env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/multiomic-classification-NSCLC/env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../RNA-Seq/RNA-ExpAll-LC.csv.gz'"
     ]
    }
   ],
   "source": [
    "all_rna = pd.read_csv('../RNA-Seq/RNA-ExpAll-LC.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['healthy', 'adeno', 'squa'])\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe.fit(classes.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcafaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, x_test, y_train_ohe, y_test_ohe, accs, f1s, name, early=False):\n",
    "    preds = {\n",
    "        'train': [],\n",
    "        'test': []\n",
    "    }\n",
    "    probs = {\n",
    "        'train': [],\n",
    "        'test': []\n",
    "    }\n",
    "    tuned_parameters = [{'max_depth': [2, 4, 6, 8],\n",
    "                            'n_estimators': [20, 30, 50, 100, 200],\n",
    "                         'alpha': [0,0.1,0.2,0.3]}]\n",
    "    \n",
    "    \n",
    "    clf = GridSearchCV(\n",
    "                    xgb.XGBClassifier(n_jobs=1,use_label_encoder=False,verbosity = 0, random_state=42), tuned_parameters, \n",
    "                    scoring='accuracy'\n",
    "                )\n",
    "    if early:\n",
    "        classes_ = [0,1,2]\n",
    "        x_train_new, y_train_ohe_new, x_val, y_val = get_val_set(x_train, y_train_ohe, classes_, percentage = 0.1)\n",
    "    else:\n",
    "        x_train_new = x_train\n",
    "        y_train_ohe_new = y_train_ohe\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x_train_new = scaler.fit_transform(x_train_new)\n",
    "    if early:\n",
    "        eval_set=[(scaler.transform(x_val), y_val.argmax(axis=1))]\n",
    "        clf.fit(x_train_new, y_train_ohe_new.argmax(axis=1), early_stopping_rounds=10, eval_set=eval_set, verbose=False)\n",
    "    else:\n",
    "        clf.fit(x_train_new, y_train_ohe_new.argmax(axis=1))\n",
    "    print(clf.best_params_)\n",
    "    x_train_new = scaler.transform(x_train)\n",
    "    y_train_ohe_new = y_train_ohe\n",
    "\n",
    "    best_params = clf.best_params_\n",
    "    train_preds = clf.predict(x_train_new)\n",
    "    preds['train'] = train_preds\n",
    "    corrects = np.sum(train_preds == y_train_ohe_new.argmax(axis=1))\n",
    "    train_acc = (corrects / x_train_new.shape[0]) * 100\n",
    "    train_f1 = f1_score(y_train_ohe_new.argmax(axis=1), train_preds, average='weighted')\n",
    "    accs['train'][name].append(train_acc)\n",
    "    f1s['train'][name].append(train_f1)\n",
    "    train_probs = clf.predict_proba(x_train_new)\n",
    "    probs['train'] = train_probs\n",
    "    print('{} Train acc: {}'.format(name, train_acc))\n",
    "    print('{} Train F1: {}'.format(name, train_f1))\n",
    "    print('CM \\n')\n",
    "    print(confusion_matrix(y_train_ohe_new.argmax(axis=1), train_preds))\n",
    "\n",
    "    #svm_ = SVC(**best_params)\n",
    "    #print(clf.best_params_)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    test_preds = clf.predict(x_test)\n",
    "    preds['test'] = test_preds\n",
    "    corrects = np.sum(test_preds == y_test_ohe.argmax(axis=1))\n",
    "    test_acc = (corrects / x_test.shape[0]) * 100\n",
    "    test_f1 = f1_score(y_test_ohe.argmax(axis=1), test_preds, average='weighted')\n",
    "    accs['test'][name].append(test_acc)\n",
    "    f1s['test'][name].append(test_f1)\n",
    "    test_probs = clf.predict_proba(x_test)\n",
    "    probs['test'] = test_probs\n",
    "    print('{} test acc: {}'.format(name, test_acc))\n",
    "    print('{} test F1: {}'.format(name, test_f1))\n",
    "    print('CM \\n')\n",
    "    print(confusion_matrix(y_test_ohe.argmax(axis=1), test_preds))\n",
    "    \n",
    "    return accs, f1s, probs, preds\n",
    "\n",
    "def get_val_set(x, y, classes, percentage = 0.1):\n",
    "    np.random.seed(42)  \n",
    "    x_train = np.array([]).reshape(0,x.shape[1])\n",
    "    y_train = np.array([]).reshape(0,y.shape[1])\n",
    "    x_val = np.array([]).reshape(0,x.shape[1])\n",
    "    y_val = np.array([]).reshape(0,y.shape[1])\n",
    "    for c in classes:\n",
    "        indexes = np.where(y.argmax(axis=1) == c)[0]\n",
    "        np.random.shuffle(indexes)\n",
    "        len_val = int(percentage * len(indexes))\n",
    "        len_train = len(indexes) - len_val\n",
    "        index_train = indexes[0:len_train]\n",
    "        index_val = indexes[len_train:]\n",
    "        x_train = np.concatenate([x_train, x[index_train,...]], axis=0)\n",
    "        y_train = np.concatenate([y_train, y[index_train]], axis=0)\n",
    "        x_val = np.concatenate([x_val, x[index_val,...]], axis=0)\n",
    "        y_val = np.concatenate([y_val, y[index_val]], axis=0)\n",
    "    \n",
    "    index_train = list(range(x_train.shape[0]))\n",
    "    index_val = list(range(x_val.shape[0]))\n",
    "    np.random.shuffle(index_train)\n",
    "    np.random.shuffle(index_val)\n",
    "    \n",
    "    return x_train[index_train,...],y_train[index_train], x_val[index_val,...], y_val[index_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 10\n",
    "path_rna_mrmr = '../RNA-Seq/mrmrDEGs/'\n",
    "path_cnv_mrmr = '../Copy-Number-Variation/mrmrDEGs/'\n",
    "n_genes_rna = 6\n",
    "n_genes_cnv = 12\n",
    "\n",
    "path = '../Copy-Number-Variation/Splits_10CV/'\n",
    "\n",
    "accs = {\n",
    "    'train': {'Integration': [], 'RNA': [], 'CNV': []},\n",
    "    'test': {'Integration': [], 'RNA': [], 'CNV': []}\n",
    "}\n",
    "f1s = {\n",
    "    'train': {'Integration': [], 'RNA': [], 'CNV': []},\n",
    "    'test': {'Integration': [], 'RNA': [], 'CNV': []}\n",
    "}\n",
    "\n",
    "preds_all = {\n",
    "    'train': {'Integration': np.array([]), 'RNA': np.array([]), 'CNV': np.array([])},\n",
    "    'test': {'Integration': np.array([]), 'RNA': np.array([]), 'CNV': np.array([])}\n",
    "}\n",
    "\n",
    "probs_all = {\n",
    "    'train': {'Integration': np.array([[],[],[]]), 'RNA': np.array([[],[],[]]), 'CNV': np.array([[],[],[]])},\n",
    "    'test': {'Integration': np.array([[],[],[]]), 'RNA': np.array([[],[],[]]), 'CNV': np.array([[],[],[]])}\n",
    "}\n",
    "\n",
    "save_xlsx = False\n",
    "if save_xlsx:\n",
    "    writer_train = pd.ExcelWriter('early_integration/RNA6_CNV12_train.xlsx', engine='openpyxl')\n",
    "    writer_test = pd.ExcelWriter('early_integration/RNA6_CNV12_test.xlsx', engine='openpyxl')\n",
    "    \n",
    "for split in tqdm(range(splits)):\n",
    "    df_rna = pd.read_csv(path_rna_mrmr+'mrmrDEGs_LC_3classes_split'+str(split)+'.csv')\n",
    "    df_cnv = pd.read_csv(path_cnv_mrmr+'mrmrDEGs_LC_CNV_3classes_p0-001_m0-1_cov3_split'+str(split)+'.csv')\n",
    "    rna_columns_keep = df_rna.columns.values[0:n_genes_rna+1].tolist()\n",
    "    cnv_columns_keep = df_cnv.columns.values[0:n_genes_cnv+1].tolist()\n",
    "    df_rna = df_rna[rna_columns_keep]\n",
    "    df_cnv = df_cnv[cnv_columns_keep]\n",
    "    data = df_rna.set_index('Case_IDs').join(df_cnv.set_index('Case_IDs'))\n",
    "    data = data.dropna()\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "\n",
    "    train_final = []\n",
    "    for i in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(train_cids),list(data['Case_IDs'].values)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for j in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(val_cids),list(data['Case_IDs'].values)[j])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(j)\n",
    "\n",
    "    #train_final.insert(0, 1)\n",
    "    #val_final.insert(0, 1)\n",
    "    df_train = data.iloc[train_final,]\n",
    "    df_val = data.iloc[val_final,]\n",
    "    \n",
    "    case_ids_val = df_val['Case_IDs']\n",
    "    #val_df_all = data_all[case_ids_val]\n",
    "    y_val = all_rna['labelsAll'].loc[all_rna['Case_IDs'].isin(case_ids_val)].values\n",
    "    #y_val = np.where(y_val == 'Blood Derived Normal', 'healthy', y_val)\n",
    "    y_val = np.where(y_val == 'Healthy', 'healthy', y_val)\n",
    "    y_val = np.where(y_val == 'Adenocarcinoma', 'adeno', y_val)\n",
    "    y_val = np.where(y_val == 'Squamous', 'squa', y_val)\n",
    "    \n",
    "    case_ids_train = df_train['Case_IDs']\n",
    "    #train_df_all = data_all[case_ids_train]\n",
    "    y_train = all_rna['labelsAll'].loc[all_rna['Case_IDs'].isin(case_ids_train)].values\n",
    "    #y_train = np.where(y_train == 'Blood Derived Normal', 'healthy', y_train)\n",
    "    y_train = np.where(y_train == 'Healthy', 'healthy', y_train)\n",
    "    y_train = np.where(y_train == 'Adenocarcinoma', 'adeno', y_train)\n",
    "    y_train = np.where(y_train == 'Squamous', 'squa', y_train)\n",
    "    \n",
    "    x_train = df_train.iloc[:,1:].values\n",
    "    x_val = df_val.iloc[:,1:].values\n",
    "    \n",
    "    y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "    y_val_ohe = ohe.transform(y_val.reshape(-1,1))\n",
    "    \n",
    "    x_train_rna = df_train.iloc[:, 1:n_genes_rna+1].values\n",
    "    x_val_rna = df_val.iloc[:, 1:n_genes_rna+1].values\n",
    "    \n",
    "    x_train_cnv = df_train.iloc[:, n_genes_rna+1:].values\n",
    "    x_val_cnv = df_val.iloc[:, n_genes_rna+1:].values\n",
    "    \n",
    "    print('End data read...')\n",
    "    \n",
    "    print('RNA training...')\n",
    "    name = 'RNA'\n",
    "    accs, f1s, probs_rna, preds_rna = train(x_train_rna, x_val_rna, y_train_ohe, y_val_ohe, accs, f1s, name, early=True)\n",
    "    preds_all['train'][name] = np.concatenate([preds_all['train'][name], preds_rna['train']], axis=0)\n",
    "    preds_all['test'][name] = np.concatenate([preds_all['test'][name], preds_rna['test']], axis=0)\n",
    "    \n",
    "    print('CNV training...')\n",
    "    name = 'CNV'\n",
    "    accs, f1s, probs_cnv, preds_cnv = train(x_train_cnv, x_val_cnv, y_train_ohe, y_val_ohe, accs, f1s, name, early=True)\n",
    "    preds_all['train'][name] = np.concatenate([preds_all['train'][name], preds_cnv['train']], axis=0)\n",
    "    preds_all['test'][name] = np.concatenate([preds_all['test'][name], preds_cnv['test']], axis=0)\n",
    "    \n",
    "    print('Integration training...')\n",
    "    name = 'Integration'\n",
    "    accs, f1s, probs_int, preds_int = train(x_train, x_val, y_train_ohe, y_val_ohe, accs, f1s, name, early=True)\n",
    "    preds_all['train'][name] = np.concatenate([preds_all['train'][name], preds_int['train']], axis=0)\n",
    "    preds_all['test'][name] = np.concatenate([preds_all['test'][name], preds_int['test']], axis=0)\n",
    "    \n",
    "    if save_xlsx:\n",
    "        # save test\n",
    "        data_test = pd.DataFrame()\n",
    "        data_test['Case IDs'] = case_ids_val\n",
    "        data_test['Has RNA'] = np.ones(len(case_ids_val))\n",
    "        data_test['Has CNV'] = np.ones(len(case_ids_val))\n",
    "        data_test['RNA Prob LUAD'] = probs_rna['test'][:,0]\n",
    "        data_test['RNA Prob HLT'] = probs_rna['test'][:,1]\n",
    "        data_test['RNA Prob LUSC'] = probs_rna['test'][:,2]\n",
    "        data_test['RNA Pred'] = preds_rna['test']\n",
    "        data_test['CNV Prob LUAD'] = probs_cnv['test'][:,0]\n",
    "        data_test['CNV Prob HLT'] = probs_cnv['test'][:,1]\n",
    "        data_test['CNV Prob LUSC'] = probs_cnv['test'][:,2]\n",
    "        data_test['CNV Pred'] = preds_cnv['test']\n",
    "        data_test['Intregation Prob LUAD'] = probs_int['test'][:,0]\n",
    "        data_test['Integration Prob HLT'] = probs_int['test'][:,1]\n",
    "        data_test['Integration Prob LUSC'] = probs_int['test'][:,2]\n",
    "        data_test['Integration Pred'] = preds_int['test']\n",
    "        data_test['Real'] = y_val_ohe.argmax(axis=1)\n",
    "        data_test.to_excel(writer_test, sheet_name='split_'+str(split), index=False)\n",
    "\n",
    "        # save train\n",
    "        data_train = pd.DataFrame()\n",
    "        data_train['Case IDs'] = case_ids_train\n",
    "        data_test['Has RNA'] = np.ones(len(case_ids_train))\n",
    "        data_test['Has CNV'] = np.ones(len(case_ids_train))\n",
    "        data_train['RNA Prob LUAD'] = probs_rna['train'][:,0]\n",
    "        data_train['RNA Prob HLT'] = probs_rna['train'][:,1]\n",
    "        data_train['RNA Prob LUSC'] = probs_rna['train'][:,2]\n",
    "        data_train['RNA Pred'] = preds_rna['train']\n",
    "        data_train['CNV Prob LUAD'] = probs_cnv['train'][:,0]\n",
    "        data_train['CNV Prob HLT'] = probs_cnv['train'][:,1]\n",
    "        data_train['CNV Prob LUSC'] = probs_cnv['train'][:,2]\n",
    "        data_train['CNV Pred'] = preds_cnv['train']\n",
    "        data_train['Integration Prob LUAD'] = probs_int['train'][:,0]\n",
    "        data_train['Integration Prob HLT'] = probs_int['train'][:,1]\n",
    "        data_train['Integration Prob LUSC'] = probs_int['train'][:,2]\n",
    "        data_train['Integration Pred'] = preds_int['train']\n",
    "        data_train['Real'] = y_train_ohe.argmax(axis=1)\n",
    "        data_train.to_excel(writer_train, sheet_name='split_'+str(split), index=False)\n",
    "    \n",
    "if save_xlsx:\n",
    "    writer_train.close()\n",
    "    writer_test.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e60a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
