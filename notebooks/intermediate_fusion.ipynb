{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd3564a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "afaf1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, f1_score\n",
    "import xgboost as xgb\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import torch.multiprocessing\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dba594",
   "metadata": {},
   "source": [
    "# FFNN Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f629175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        \n",
    "        self.fcr = nn.Linear(input_dim['RNA'], 100)\n",
    "        self.fcc = nn.Linear(input_dim['CNV'], 100)\n",
    "        \n",
    "        self.fcj = nn.Linear(200, 40)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(200)\n",
    "        self.bn2 = nn.BatchNorm1d(40)\n",
    "        \n",
    "        self.fc = nn.Linear(40,3)\n",
    "\n",
    "        \n",
    "    def forward(self, x1, x2, test=False):\n",
    "        \n",
    "        out1 = F.dropout(x1, 0.4, training=self.training)\n",
    "        out1 = torch.tanh(self.fcr(out1))\n",
    "        \n",
    "        out2 = F.dropout(x2, 0.4, training=self.training)\n",
    "        out2 = torch.tanh(self.fcc(out2))\n",
    "        \n",
    "        x = torch.cat([out1,out2], axis=1)\n",
    "        x = self.bn1(x)\n",
    "        x = F.dropout(x, 0.5, training=self.training)\n",
    "        x = self.fcj(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class FFNNDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, inputs, labels):\n",
    "        'Initialization'\n",
    "        self.inputs_rna = inputs['RNA']\n",
    "        self.inputs_cnv = inputs['CNV']\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.inputs_rna)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        x_rna = torch.from_numpy(self.inputs_rna[index]).float()\n",
    "        x_cnv = torch.from_numpy(self.inputs_cnv[index]).float()\n",
    "        label = torch.from_numpy(self.labels[index]).float()\n",
    "        return x_rna, x_cnv, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297f3c96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscocp/multiomic-classification-NSCLC/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "all_rna = pd.read_csv('../RNA-Seq/RNA-ExpAll-LC.csv.gz', compression='gzip')\n",
    "all_cnv = pd.read_csv('../Copy-Number-Variation/gene_matrix_CNV_noNA.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab4da175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(sparse=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.array(['healthy', 'adeno', 'squa'])\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe.fit(classes.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2beaa5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_set(x, y, classes, percentage = 0.1):\n",
    "    np.random.seed(42)  \n",
    "    x_train = np.array([]).reshape(0,x.shape[1])\n",
    "    y_train = np.array([]).reshape(0,y.shape[1])\n",
    "    x_val = np.array([]).reshape(0,x.shape[1])\n",
    "    y_val = np.array([]).reshape(0,y.shape[1])\n",
    "    for c in classes:\n",
    "        indexes = np.where(y.argmax(axis=1) == c)[0]\n",
    "        np.random.shuffle(indexes)\n",
    "        len_val = int(percentage * len(indexes))\n",
    "        len_train = len(indexes) - len_val\n",
    "        index_train = indexes[0:len_train]\n",
    "        index_val = indexes[len_train:]\n",
    "        x_train = np.concatenate([x_train, x[index_train,...]], axis=0)\n",
    "        y_train = np.concatenate([y_train, y[index_train]], axis=0)\n",
    "        x_val = np.concatenate([x_val, x[index_val,...]], axis=0)\n",
    "        y_val = np.concatenate([y_val, y[index_val]], axis=0)\n",
    "    \n",
    "    index_train = list(range(x_train.shape[0]))\n",
    "    index_val = list(range(x_val.shape[0]))\n",
    "    np.random.shuffle(index_train)\n",
    "    np.random.shuffle(index_val)\n",
    "    \n",
    "    return x_train[index_train,...],y_train[index_train], x_val[index_val,...], y_val[index_val]\n",
    "\n",
    "def weights_init(m):\n",
    "    # Xavier weight initialization\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "84215a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8b8ff8233245fd85e5e24753ed4fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-269-580fd088873a>\u001b[0m(99)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     97 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     98 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 99 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'End data read...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    100 \u001b[0;31m    \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    101 \u001b[0;31m    \u001b[0mx_train_rna_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ohe_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_rna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_val_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_rna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ohe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> x_train_rna.shape\n",
      "(812, 371)\n",
      "ipdb> x_train_cnv.shape\n",
      "(812, 1798)\n",
      "ipdb> exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-580fd088873a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'End data read...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mx_train_rna_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ohe_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_rna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_val_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_rna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ohe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-269-580fd088873a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'End data read...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mx_train_rna_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ohe_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_rna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_ohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_val_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_rna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ohe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "splits = 10\n",
    "path = '../Copy-Number-Variation/Splits_10CV/'\n",
    "\n",
    "save_xlsx = False\n",
    "accs = []\n",
    "test_preds_all = []\n",
    "test_labels_all = []\n",
    "\n",
    "if save_xlsx:\n",
    "    writer = pd.ExcelWriter('early_integration/intermediate_integration_test.xlsx', engine='openpyxl')\n",
    "    \n",
    "for split in tqdm(range(splits)):\n",
    "    name_cnv = '../Copy-Number-Variation/p-valueDEGsAll/DEGs_CNV_train'+str(split)+'_p0-001_m0-1_cov3.csv'\n",
    "    name_rna = '../RNA-Seq/limma-degs/limmadegs_RNA_train'+str(split)+'_lfc1-5_p0-001_cov2.csv'\n",
    "    \n",
    "    # RNA\n",
    "    degs_rna = pd.read_csv(name_rna)\n",
    "    columns = np.concatenate([['Case_IDs'], degs_rna['x'].values], axis=0)\n",
    "    df_rna = all_rna[columns]\n",
    "    \n",
    "    # CNV\n",
    "    df_cnv = pd.read_csv(name_cnv)\n",
    "    df_cnv = df_cnv.rename({'Unnamed: 0': 'Case_IDs'}, axis=1)\n",
    "    \n",
    "    equal_case_ids = list(set(df_cnv['Case_IDs'].values) & set(df_rna['Case_IDs'].values))\n",
    "    df_rna = df_rna.loc[df_rna['Case_IDs'].isin(equal_case_ids)]\n",
    "    df_cnv = df_cnv.loc[df_cnv['Case_IDs'].isin(equal_case_ids)]\n",
    "    assert df_rna.shape[0] == df_cnv.shape[0]\n",
    "        \n",
    "    train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "\n",
    "    train_final = []\n",
    "    for i in range(len(list(df_rna['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(train_cids),list(df_rna['Case_IDs'].values)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for j in range(len(list(df_rna['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(val_cids),list(df_rna['Case_IDs'].values)[j])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(j)\n",
    "\n",
    "    df_train_rna = df_rna.iloc[train_final,]\n",
    "    df_test_rna = df_rna.iloc[val_final,]\n",
    "    \n",
    "    df_train_cnv = df_cnv.iloc[train_final,]\n",
    "    df_test_cnv = df_cnv.iloc[val_final,]\n",
    "    \n",
    "    case_ids_test = df_test_rna['Case_IDs']\n",
    "    y_test = all_rna['labelsAll'].loc[all_rna['Case_IDs'].isin(case_ids_test)].values\n",
    "    y_test = np.where(y_test == 'Healthy', 'healthy', y_test)\n",
    "    y_test = np.where(y_test == 'Adenocarcinoma', 'adeno', y_test)\n",
    "    y_test = np.where(y_test == 'Squamous', 'squa', y_test)\n",
    "    \n",
    "    case_ids_train = df_train_rna['Case_IDs']\n",
    "    y_train = all_rna['labelsAll'].loc[all_rna['Case_IDs'].isin(case_ids_train)].values\n",
    "    y_train = np.where(y_train == 'Healthy', 'healthy', y_train)\n",
    "    y_train = np.where(y_train == 'Adenocarcinoma', 'adeno', y_train)\n",
    "    y_train = np.where(y_train == 'Squamous', 'squa', y_train)\n",
    "     \n",
    "    y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "    y_test_ohe = ohe.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "    x_train_rna = df_train_rna.iloc[:, 1:].values\n",
    "    x_test_rna = df_test_rna.iloc[:, 1:].values\n",
    "    \n",
    "    x_train_cnv = df_train_cnv.iloc[:, 1:].values\n",
    "    x_test_cnv = df_test_cnv.iloc[:, 1:].values\n",
    "    \n",
    "    print('End data read...')\n",
    "    classes_ = [0,1,2]\n",
    "    x_train_rna_new, y_train_ohe_new, x_val_rna, y_val_ohe = get_val_set(x_train_rna, y_train_ohe, classes_, percentage = 0.1)\n",
    "    x_train_cnv_new, _, x_val_cnv, _ = get_val_set(x_train_cnv, y_train_ohe, classes_, percentage = 0.1)\n",
    "    \n",
    "    # FFNN\n",
    "    \n",
    "    scaler_rna = StandardScaler()\n",
    "    scaler_cnv = StandardScaler()\n",
    "    x_train_rna_new = scaler_rna.fit_transform(x_train_rna_new)\n",
    "    x_val_rna = scaler_rna.transform(x_val_rna)\n",
    "    x_test_rna = scaler_rna.transform(x_test_rna)\n",
    "    \n",
    "    x_train_cnv_new = scaler_cnv.fit_transform(x_train_cnv_new)\n",
    "    x_val_cnv = scaler_cnv.transform(x_val_cnv)\n",
    "    x_test_cnv = scaler_cnv.transform(x_test_cnv)\n",
    "    \n",
    "    train = {'RNA': x_train_rna_new, 'CNV': x_train_cnv_new}\n",
    "    val = {'RNA': x_val_rna, 'CNV': x_val_cnv}\n",
    "    test = {'RNA': x_test_rna, 'CNV': x_test_cnv}\n",
    "    \n",
    "    dataset_train = FFNNDataset(train, y_train_ohe_new)\n",
    "    dataset_val = FFNNDataset(val, y_val_ohe)\n",
    "    dataset_test = FFNNDataset(test, y_test_ohe)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=64,\n",
    "                                  shuffle=True, num_workers=4,\n",
    "                                  pin_memory=False)\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size=1,\n",
    "                                  shuffle=True, num_workers=4,\n",
    "                                  pin_memory=False)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=1,\n",
    "                                  shuffle=False, num_workers=4,\n",
    "                                  pin_memory=False)\n",
    "    \n",
    "    input_dim = {\n",
    "        'RNA': x_train_rna.shape[1],\n",
    "        'CNV': x_train_cnv.shape[1]\n",
    "    }\n",
    "\n",
    "    output_dim = 3\n",
    "\n",
    "    model = FFNN(input_dim, output_dim)\n",
    "\n",
    "    model.apply(weights_init)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3,weight_decay=0)\n",
    "    losses = []\n",
    "    num_epochs = 15\n",
    "    dataloaders = {\n",
    "        'train': dataloader_train,\n",
    "        'val': dataloader_val\n",
    "    }\n",
    "    \n",
    "    # Start training\n",
    "    best_epoch = 0\n",
    "    best_acc = 100\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_labels_auc = []\n",
    "    val_preds_auc = []\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "    train_preds_auc = []\n",
    "    train_labels_auc = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    losses = {\n",
    "        'train': [],\n",
    "        'val': []\n",
    "    }\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        batch_loss = 0\n",
    "        sizes = {}\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            sizes[phase] = 0\n",
    "            running_loss = 0\n",
    "            running_corrects = 0\n",
    "            for inputs_rna,inputs_cnv, labels in dataloaders[phase]:\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs_rna,inputs_cnv)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    _, mlabels = torch.max(labels, 1)\n",
    "                    \n",
    "                    loss = criterion(outputs, mlabels)\n",
    "                if phase == 'val':\n",
    "                    val_preds += list(preds.numpy())\n",
    "                    val_labels += list(mlabels.numpy())\n",
    "                    val_labels_auc += [labels.numpy()]\n",
    "                    val_preds_auc += [preds.numpy()]\n",
    "\n",
    "                \n",
    "                # Accumulating the loss over time\n",
    "                running_loss += loss.item() * inputs_rna.size(0)\n",
    "                running_corrects += torch.sum(preds == mlabels)\n",
    "                sizes[phase] += inputs_rna.size(0)\n",
    "                \n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    train_preds += list(preds.numpy())\n",
    "                    train_labels += list(mlabels.numpy())\n",
    "                    train_labels_auc += [labels.numpy()]\n",
    "                    train_preds_auc += [preds.numpy()]\n",
    "                    # Getting gradients w.r.t. parameters\n",
    "                    loss.backward()\n",
    "\n",
    "                    # Updating parameters\n",
    "                    optimizer.step()\n",
    "                \n",
    "            epoch_loss = running_loss / sizes[phase]\n",
    "            epoch_acc = running_corrects.item() / sizes[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc))\n",
    "            losses[phase].append(epoch_loss)\n",
    "            if phase == 'val' and epoch_loss < best_acc:\n",
    "                best_epoch = epoch\n",
    "                best_acc = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "                    \n",
    "    print('Best epoch {}'.format(best_epoch))\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(list(range(num_epochs)),losses['train'], label='train', color='blue')\n",
    "    plt.plot(list(range(num_epochs)),losses['val'], label='val', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Test in validation set\n",
    "    \n",
    "    sizes = 0\n",
    "        \n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "    running_loss = 0\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    test_labels_auc = []\n",
    "    test_preds_auc = []\n",
    "    test_probs_luad = []\n",
    "    test_probs_hlt = []\n",
    "    test_probs_lusc = []\n",
    "    phase = 'test'\n",
    "    for inputs_rna,inputs_cnv, labels in dataloader_test:\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            outputs = model(inputs_rna,inputs_cnv, test=True)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, mlabels = torch.max(labels, 1)\n",
    "\n",
    "            loss = criterion(outputs, mlabels)\n",
    "        # Accumulating the loss over time\n",
    "        running_loss += loss.item() * inputs_rna.size(0)\n",
    "        running_corrects += torch.sum(preds == mlabels)\n",
    "        sizes += inputs_rna.size(0)\n",
    "        test_preds += list(preds.cpu().numpy())\n",
    "        test_labels += list(mlabels.numpy())\n",
    "        test_probs = probs.numpy()[0]\n",
    "        test_probs_luad += [test_probs[0]]\n",
    "        test_probs_hlt += [test_probs[1]]\n",
    "        test_probs_lusc += [test_probs[2]]\n",
    "        test_labels_auc += [labels.numpy()]\n",
    "        test_preds_auc += [preds.numpy()]\n",
    "    epoch_loss = running_loss / sizes\n",
    "    epoch_acc = running_corrects.item() / sizes\n",
    "    print('Test Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "    accs.append(epoch_acc)\n",
    "    test_preds_all.append(test_preds)\n",
    "    test_labels_all.append(test_labels)\n",
    "    \n",
    "    if save_xlsx:\n",
    "        data_test = pd.DataFrame()\n",
    "        data_test['Case IDs'] = case_ids_test\n",
    "        data_test['Intregation Prob LUAD'] = test_probs_luad\n",
    "        data_test['Integration Prob HLT'] = test_probs_hlt\n",
    "        data_test['Integration Prob LUSC'] = test_probs_lusc\n",
    "        data_test['Integration Pred'] = test_preds\n",
    "        data_test['Real'] = y_test_ohe.argmax(axis=1)\n",
    "        data_test.to_excel(writer, sheet_name='split_'+str(split), index=False)\n",
    "\n",
    "if save_xlsx:\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
